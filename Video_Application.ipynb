{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tensorflow/docs\n",
        "!pip install tensorflow\n",
        "!pip install imutils\n",
        "!pip install opencv-python\n",
        "!pip install imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "podQcIZw9E0E",
        "outputId": "220e6338-fac9-47f2-8665-3ef0d2385acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-sylj9jj8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-sylj9jj8\n",
            "  Resolved https://github.com/tensorflow/docs to commit 3688f3cff2685cfeab307c13435f77d2c96cf434\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (3.1.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.2.5.73858) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.2.5.73858) (2.1.5)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.7.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.2.5.73858) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.2.5.73858) (0.18.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2024.2.5.73858) (4.2.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0vBzXeqBkXP",
        "outputId": "544c2602-f022-474a-a83c-1f27520f9cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/VAD/Football_video_dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H49VK4TB0R3",
        "outputId": "1d041576-2147-425a-c983-b568b6b9f473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/VAD/Football_video_dataset.zip\n",
            "replace Football_video_dataset/test/Goal/goal (107).avi? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Bidirectional, Dropout, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n"
      ],
      "metadata": {
        "id": "Hg1K3x-VnmU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.listdir('Football_video_dataset/train')\n",
        "\n",
        "# Check if directories exist\n",
        "train_dir = 'Football_video_dataset/train'\n",
        "test_dir = 'Football_video_dataset/test'\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Training or testing directories do not exist.\")\n",
        "\n",
        "label_types = os.listdir('Football_video_dataset/train')\n",
        "print (label_types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoPr7l5_B0WP",
        "outputId": "de331fbf-64bc-409e-d058-303de51599d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Goal', 'Loss', 'Happy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_list = []\n",
        "\n",
        "for item in dataset_path:\n",
        "\n",
        " # Get all the file names\n",
        " all_video_list = os.listdir('Football_video_dataset/train' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for video in all_video_list:\n",
        "    video_list.append((item, str('Football_video_dataset/train' + '/' +item) + '/' + video))\n",
        "\n",
        "# Build a dataframe\n",
        "train_df = pd.DataFrame(data=video_list, columns=['tag', 'video_name'])\n",
        "print(train_df.head())\n",
        "print(train_df.tail())\n",
        "df = train_df.loc[:,['video_name','tag']]\n",
        "df.to_csv('train.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMTWAZbHB0b4",
        "outputId": "e4db3be6-6997-4633-94e5-daee792d5903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    tag                                       video_name\n",
            "0  Goal  Football_video_dataset/train/Goal/goal (23).avi\n",
            "1  Goal  Football_video_dataset/train/Goal/goal (66).avi\n",
            "2  Goal  Football_video_dataset/train/Goal/goal (89).avi\n",
            "3  Goal  Football_video_dataset/train/Goal/goal (18).avi\n",
            "4  Goal   Football_video_dataset/train/Goal/goal (9).avi\n",
            "       tag                                         video_name\n",
            "313  Happy  Football_video_dataset/train/Happy/Happy (37).mp4\n",
            "314  Happy  Football_video_dataset/train/Happy/Happy (70).mp4\n",
            "315  Happy  Football_video_dataset/train/Happy/Happy (55).mp4\n",
            "316  Happy  Football_video_dataset/train/Happy/Happy (32).mp4\n",
            "317  Happy  Football_video_dataset/train/Happy/Happy (43).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.listdir('Football_video_dataset/test')\n",
        "print(dataset_path)\n",
        "\n",
        "video_list = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_video_list = os.listdir('Football_video_dataset/test' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for video in all_video_list:\n",
        "    video_list.append((item, str('Football_video_dataset/test' + '/' +item) + '/' + video))\n",
        "\n",
        "# Build a dataframe\n",
        "test_df = pd.DataFrame(data=video_list, columns=['tag', 'video_name'])\n",
        "print(test_df.head())\n",
        "print(test_df.tail())\n",
        "\n",
        "df = test_df.loc[:,['video_name','tag']]\n",
        "df.to_csv('test.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mno587VB0nE",
        "outputId": "047e5543-1ac7-4fcb-9cec-6dfaa1bf319f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Goal', 'Loss', 'Happy']\n",
            "    tag                                       video_name\n",
            "0  Goal  Football_video_dataset/test/Goal/goal (114).avi\n",
            "1  Goal  Football_video_dataset/test/Goal/goal (119).avi\n",
            "2  Goal  Football_video_dataset/test/Goal/goal (111).avi\n",
            "3  Goal  Football_video_dataset/test/Goal/goal (117).avi\n",
            "4  Goal  Football_video_dataset/test/Goal/goal (107).avi\n",
            "      tag                                         video_name\n",
            "73  Happy  Football_video_dataset/test/Happy/Happy (108).mp4\n",
            "74  Happy  Football_video_dataset/test/Happy/Happy (122).mp4\n",
            "75  Happy  Football_video_dataset/test/Happy/Happy (120).mp4\n",
            "76  Happy  Football_video_dataset/test/Happy/Happy (116).mp4\n",
            "77  Happy  Football_video_dataset/test/Happy/Happy (110).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "\n",
        "\n",
        "train_df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "6KWkUCVQFZ5P",
        "outputId": "ac2b96b4-7623-463e-a938-65d3838d71ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 318\n",
            "Total videos for testing: 78\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                         video_name    tag\n",
              "69           69    Football_video_dataset/train/Goal/goal (71).avi   Goal\n",
              "112         112    Football_video_dataset/train/Loss/Loss (20).avi   Loss\n",
              "226         226  Football_video_dataset/train/Happy/Happy (36).mp4  Happy\n",
              "183         183    Football_video_dataset/train/Loss/Loss (72).avi   Loss\n",
              "162         162    Football_video_dataset/train/Loss/Loss (79).avi   Loss\n",
              "2             2    Football_video_dataset/train/Goal/goal (89).avi   Goal\n",
              "298         298  Football_video_dataset/train/Happy/Happy (22).mp4  Happy\n",
              "250         250  Football_video_dataset/train/Happy/Happy (86).mp4  Happy\n",
              "43           43     Football_video_dataset/train/Goal/goal (8).avi   Goal\n",
              "25           25    Football_video_dataset/train/Goal/goal (12).avi   Goal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c959baed-77fa-4e59-900b-5df40450abdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>69</td>\n",
              "      <td>Football_video_dataset/train/Goal/goal (71).avi</td>\n",
              "      <td>Goal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>112</td>\n",
              "      <td>Football_video_dataset/train/Loss/Loss (20).avi</td>\n",
              "      <td>Loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>226</td>\n",
              "      <td>Football_video_dataset/train/Happy/Happy (36).mp4</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>183</td>\n",
              "      <td>Football_video_dataset/train/Loss/Loss (72).avi</td>\n",
              "      <td>Loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>162</td>\n",
              "      <td>Football_video_dataset/train/Loss/Loss (79).avi</td>\n",
              "      <td>Loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Football_video_dataset/train/Goal/goal (89).avi</td>\n",
              "      <td>Goal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>298</td>\n",
              "      <td>Football_video_dataset/train/Happy/Happy (22).mp4</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>250</td>\n",
              "      <td>Football_video_dataset/train/Happy/Happy (86).mp4</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>Football_video_dataset/train/Goal/goal (8).avi</td>\n",
              "      <td>Goal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>Football_video_dataset/train/Goal/goal (12).avi</td>\n",
              "      <td>Goal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c959baed-77fa-4e59-900b-5df40450abdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c959baed-77fa-4e59-900b-5df40450abdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c959baed-77fa-4e59-900b-5df40450abdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28848936-b1c9-424e-9d1a-c5fc4125d5e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28848936-b1c9-424e-9d1a-c5fc4125d5e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28848936-b1c9-424e-9d1a-c5fc4125d5e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102,\n        \"min\": 2,\n        \"max\": 298,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          43,\n          112,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Football_video_dataset/train/Goal/goal (8).avi\",\n          \"Football_video_dataset/train/Loss/Loss (20).avi\",\n          \"Football_video_dataset/train/Goal/goal (89).avi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Goal\",\n          \"Loss\",\n          \"Happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n"
      ],
      "metadata": {
        "id": "yrlECbDy2xLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.applications import InceptionV3\n",
        "import keras\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "def build_feature_extractor():\n",
        "    # Load InceptionV3 model with pre-trained weights\n",
        "    base_model = InceptionV3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze the pre-trained layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Global average pooling layer to reduce spatial dimensions\n",
        "    global_average_layer = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "    # Add custom dense layers for your task\n",
        "    dense_layer = layers.Dense(256, activation='relu')(global_average_layer)\n",
        "    dropout_layer = layers.Dropout(0.5)(dense_layer)\n",
        "\n",
        "    # Output layer with the number of classes in your task\n",
        "    output_layer = layers.Dense(NUM_CLASSES, activation='softmax')(dropout_layer)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Model(inputs=base_model.input, outputs=output_layer, name='feature_extractor')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the InceptionV3 feature extractor\n",
        "feature_extractor = build_feature_extractor()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FstQi022xOY",
        "outputId": "2c030648-04c1-4a6e-8545-6c475d0accd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 256\n",
        "NUM_CLASSES = 3"
      ],
      "metadata": {
        "id": "Ucy9Bbl_13ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label processing\n",
        "label_processor = Tokenizer()\n",
        "labels = train_df[\"tag\"].values\n",
        "label_processor.fit_on_texts(labels)\n",
        "train_labels_numeric = np.array(label_processor.texts_to_sequences(labels)) - 1"
      ],
      "metadata": {
        "id": "rlu91F9j2Gza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_all_videos(df, folder, root_dir, MAX_SEQ_LENGTH, NUM_FEATURES):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "\n",
        "    # Take all class labels from train_df column named 'tag' and store in labels\n",
        "    labels = df[\"tag\"].values\n",
        "\n",
        "    # Tokenize labels\n",
        "    label_processor = Tokenizer()\n",
        "    label_processor.fit_on_texts(labels)\n",
        "    labels = np.array(label_processor.texts_to_sequences(labels)) - 1\n",
        "\n",
        "    # Frame masks and frame features\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    # For each video\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "        # Extract features from frames\n",
        "        for i in range(frames.shape[1]):\n",
        "            temp_frame_features[0, i, :] = build_feature_extractor(frames[0, i, :])\n",
        "            temp_frame_mask[0, i] = 1\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return [frame_features, frame_masks], labels\n"
      ],
      "metadata": {
        "id": "EKB3c9hr2JX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/Football_video_dataset'\n",
        "\n",
        "# Load and preprocess train data\n",
        "train_data, _ = prepare_all_videos(train_df, \"train\", root_dir, MAX_SEQ_LENGTH, NUM_FEATURES)\n",
        "\n",
        "# Load and preprocess test data\n",
        "test_data, _ = prepare_all_videos(test_df, \"test\", root_dir, MAX_SEQ_LENGTH, NUM_FEATURES)\n",
        "\n",
        "# Tokenize test labels\n",
        "test_labels_numeric = np.array(label_processor.texts_to_sequences(test_df[\"tag\"].values)) - 1\n",
        "\n",
        "# Assuming sequences and masks are part of your data\n",
        "sequences_train, masks_train = train_data\n",
        "sequences_test, masks_test = test_data\n",
        "\n",
        "def get_sequence_model(num_layers=2, num_units=16):\n",
        "    class_vocab = label_processor.word_index  # Access vocabulary using word_index attribute\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Bidirectional GRU with num_units units per direction\n",
        "    x = Bidirectional(GRU(num_units, return_sequences=True))(frame_features_input, mask=mask_input)\n",
        "    x = GRU(num_units)(x)  # Maintain the final GRU layer\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(num_units, activation=\"relu\")(x)\n",
        "    output = Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "# Build the model\n",
        "model = get_sequence_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    [sequences_train, masks_train],\n",
        "    train_labels_numeric,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=([sequences_test, masks_test], test_labels_numeric),\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate([sequences_test, masks_test], test_labels_numeric)[1]\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ7C6IPZuuOC",
        "outputId": "7af0b8ca-e933-4472-d6c3-2d91b2c26aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "5/5 [==============================] - 19s 1s/step - loss: 1.0987 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.0987 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0986 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 86ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Test Accuracy: 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "neJRgFn_wHPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vYB_vO9TzJi7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}