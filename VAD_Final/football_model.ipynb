{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install imutils\n",
        "# !pip install opencv-python\n",
        "# !pip install imageio"
      ],
      "metadata": {
        "id": "Kjmc8ztySbq9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "from keras.applications import InceptionV3\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Dense, Dropout, GlobalAveragePooling2D, Bidirectional, LSTM, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "\n"
      ],
      "metadata": {
        "id": "GEYhxFVTs0vd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if directories exist\n",
        "train_dir = 'Football_video_dataset/train'\n",
        "test_dir = 'Football_video_dataset/test'\n",
        "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
        "    raise FileNotFoundError(\"Training or testing directories do not exist.\")\n",
        "\n",
        "label_types = os.listdir('Football_video_dataset/train')\n",
        "print (label_types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e_xQOvs0zF",
        "outputId": "0585237b-0c67-4036-e9c4-f29fe9e8f679"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Loss', 'Goal', 'Happy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.listdir('Football_video_dataset/train')\n",
        "print(dataset_path)\n",
        "\n",
        "video_list = []\n",
        "\n",
        "for item in dataset_path:\n",
        "\n",
        " # Get all the file names\n",
        " all_video_list = os.listdir('Football_video_dataset/train' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for video in all_video_list:\n",
        "    video_list.append((item, str('Football_video_dataset/train' + '/' +item) + '/' + video))\n",
        "\n",
        "# Build a dataframe\n",
        "train_df = pd.DataFrame(data=video_list, columns=['tag', 'video_name'])\n",
        "print(train_df.head())\n",
        "print(train_df.tail())\n",
        "df = train_df.loc[:,['video_name','tag']]\n",
        "df.to_csv('train.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAmKIEdis02A",
        "outputId": "7f7fdc64-2620-415f-edc5-57b45d41de93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Loss', 'Goal', 'Happy']\n",
            "    tag                                        video_name\n",
            "0  Loss  Football_video_dataset/train/Loss/Loss (128).avi\n",
            "1  Loss   Football_video_dataset/train/Loss/Loss (64).avi\n",
            "2  Loss   Football_video_dataset/train/Loss/Loss (87).avi\n",
            "3  Loss   Football_video_dataset/train/Loss/Loss (62).avi\n",
            "4  Loss   Football_video_dataset/train/Loss/Loss (66).avi\n",
            "       tag                                         video_name\n",
            "313  Happy  Football_video_dataset/train/Happy/Happy (94).mp4\n",
            "314  Happy  Football_video_dataset/train/Happy/Happy (87).mp4\n",
            "315  Happy  Football_video_dataset/train/Happy/Happy (37).mp4\n",
            "316  Happy  Football_video_dataset/train/Happy/Happy (27).mp4\n",
            "317  Happy  Football_video_dataset/train/Happy/Happy (12).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.listdir('Football_video_dataset/test')\n",
        "print(dataset_path)\n",
        "video_list = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_video_list = os.listdir('Football_video_dataset/test' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for video in all_video_list:\n",
        "    video_list.append((item, str('Football_video_dataset/test' + '/' +item) + '/' + video))\n",
        "\n",
        "# Build a dataframe\n",
        "test_df = pd.DataFrame(data=video_list, columns=['tag', 'video_name'])\n",
        "print(test_df.head())\n",
        "print(test_df.tail())\n",
        "\n",
        "df = test_df.loc[:,['video_name','tag']]\n",
        "df.to_csv('test.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w22Smj9AtkbO",
        "outputId": "a4c55858-cf62-44e6-80ad-dc196c2986a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Loss', 'Goal', 'Happy']\n",
            "    tag                                       video_name\n",
            "0  Loss    Football_video_dataset/test/Loss/Loss (5).avi\n",
            "1  Loss  Football_video_dataset/test/Loss/Loss (125).avi\n",
            "2  Loss  Football_video_dataset/test/Loss/Loss (122).avi\n",
            "3  Loss  Football_video_dataset/test/Loss/Loss (120).avi\n",
            "4  Loss    Football_video_dataset/test/Loss/Loss (9).avi\n",
            "      tag                                         video_name\n",
            "73  Happy  Football_video_dataset/test/Happy/Happy (123).mp4\n",
            "74  Happy  Football_video_dataset/test/Happy/Happy (128).mp4\n",
            "75  Happy  Football_video_dataset/test/Happy/Happy (119).mp4\n",
            "76  Happy  Football_video_dataset/test/Happy/Happy (115).mp4\n",
            "77  Happy  Football_video_dataset/test/Happy/Happy (129).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo-H5y3EtkeK",
        "outputId": "8dec2f3b-4a68-499e-9536-4c4b8ab9f552"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 318\n",
            "Total videos for testing: 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess video frames and save them to a folder\n",
        "\n",
        "def load_video_frames(video_path, output_folder, capture_percentage=0.6):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total video frames (estimate)\n",
        "  frame_count = 0\n",
        "\n",
        "  try:\n",
        "    if total_frames > 0:  # Check for valid total frames\n",
        "      # Calculate capture interval based on total frames and percentage\n",
        "      capture_interval = int(total_frames / (capture_percentage * total_frames))\n",
        "\n",
        "      while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "          break\n",
        "\n",
        "        # Capture logic based on capture interval\n",
        "        if frame_count % capture_interval == 0:\n",
        "          frame_path = os.path.join(output_folder, f\"frame_{frame_count}.jpg\")\n",
        "          cv2.imwrite(frame_path, frame)\n",
        "          frame_count += 1\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading video {video_path}: {e}\")\n",
        "  finally:\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "QoqeXtwO2j_h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save preprocess video frames to a folder\n",
        "def load_data(video_dir=\"Football_video_dataset\", train_folder=\"train\", test_folder=\"test\"):\n",
        "    train_labels = {}\n",
        "    train_df = pd.read_csv(os.path.join(\"train.csv\"))\n",
        "    for _, row in train_df.iterrows():\n",
        "        train_labels[row['video_name']] = row['tag']\n",
        "\n",
        "    test_labels = {}\n",
        "    test_df = pd.read_csv(os.path.join( \"test.csv\"))\n",
        "    for _, row in test_df.iterrows():\n",
        "        test_labels[row['video_name']] = row['tag']\n",
        "\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    for class_folder in os.listdir(os.path.join(video_dir, train_folder)):\n",
        "        class_path = os.path.join(video_dir, train_folder, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith((\".mp4\", \".avi\")):\n",
        "                    video_path = os.path.join(class_path, filename)\n",
        "                    output_folder = os.path.join(video_dir, train_folder + \"_frames\", class_folder, os.path.splitext(filename)[0])\n",
        "                    os.makedirs(output_folder, exist_ok=True)\n",
        "                    load_video_frames(video_path, output_folder)\n",
        "                    X_train.append(output_folder)\n",
        "                    y_train.append(train_labels.get(filename, None))\n",
        "\n",
        "    for class_folder in os.listdir(os.path.join(video_dir, test_folder)):\n",
        "        class_path = os.path.join(video_dir, test_folder, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith((\".mp4\", \".avi\")):\n",
        "                    video_path = os.path.join(class_path, filename)\n",
        "                    output_folder = os.path.join(video_dir, test_folder + \"_frames\", class_folder, os.path.splitext(filename)[0])\n",
        "                    os.makedirs(output_folder, exist_ok=True)\n",
        "                    load_video_frames(video_path, output_folder)\n",
        "                    X_test.append(output_folder)\n",
        "                    y_test.append(test_labels.get(filename, None))\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = load_data()\n",
        "\n"
      ],
      "metadata": {
        "id": "VmmcUWzM4cAo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=\"Football_video_dataset/train_frames\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=\"Football_video_dataset/test_frames\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define InceptionV3 model with transfer learning\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Reshape((1, 2048))(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout to combat overfitting\n",
        "x = Bidirectional(LSTM(128))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Output layer\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze layers in base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ModelCheckpoint callback to save the best model based on validation loss\n",
        "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# EarlyStopping callback to stop training if validation loss doesn't improve\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator, callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"football_video_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5i7pv2K9UoR",
        "outputId": "a0b388ba-bd2c-49e4-dd8a-795794305555"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 53381 images belonging to 3 classes.\n",
            "Found 6780 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9434\n",
            "Epoch 1: val_loss improved from inf to 0.48449, saving model to best_model.keras\n",
            "418/418 [==============================] - 351s 786ms/step - loss: 0.1508 - accuracy: 0.9434 - val_loss: 0.4845 - val_accuracy: 0.8906\n",
            "Epoch 2/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9801\n",
            "Epoch 2: val_loss improved from 0.48449 to 0.39243, saving model to best_model.keras\n",
            "418/418 [==============================] - 288s 689ms/step - loss: 0.0599 - accuracy: 0.9801 - val_loss: 0.3924 - val_accuracy: 0.9083\n",
            "Epoch 3/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9859\n",
            "Epoch 3: val_loss improved from 0.39243 to 0.36187, saving model to best_model.keras\n",
            "418/418 [==============================] - 270s 647ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.3619 - val_accuracy: 0.9178\n",
            "Epoch 4/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9855\n",
            "Epoch 4: val_loss did not improve from 0.36187\n",
            "418/418 [==============================] - 265s 633ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.4676 - val_accuracy: 0.9097\n",
            "Epoch 5/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9897\n",
            "Epoch 5: val_loss did not improve from 0.36187\n",
            "418/418 [==============================] - 263s 630ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.4250 - val_accuracy: 0.9192\n",
            "Epoch 6/10\n",
            "418/418 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9913\n",
            "Epoch 6: val_loss did not improve from 0.36187\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "418/418 [==============================] - 267s 638ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.4128 - val_accuracy: 0.9273\n",
            "Epoch 6: early stopping\n",
            "53/53 [==============================] - 39s 726ms/step - loss: 0.3619 - accuracy: 0.9178\n",
            "Test Loss: 0.3619, Test Accuracy: 0.9178\n"
          ]
        }
      ]
    }
  ]
}